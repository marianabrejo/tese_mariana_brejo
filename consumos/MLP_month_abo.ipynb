{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nRSlxT4q5EHJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 22:33:11.363253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-06 22:33:11.363298: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from numpy import array\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "cm = 1/2.54 \n",
    "colors = ['#4477AA', '#EE6677', '#228833', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB']\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values with Zero and Group by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2fRF6mEW5QbK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('consumos_abo.csv', parse_dates=['date'])\n",
    "df = df.set_index('date')\n",
    "df = df.groupby('abo').resample('M').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batches of training data (12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, sequence_total, n_steps_in, n_steps_out, slide):\n",
    "    X, y = list(), list()\n",
    "    for i in range(0, len(sequence), slide):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence_total[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and fit MLP model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_steps_in, n_steps_out):\n",
    "    callback = EarlyStopping(monitor='loss', patience=50)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(800, activation='relu', input_shape=(n_steps_in,)))\n",
    "    model.add(Dense(800, activation='relu', \n",
    "                kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "                bias_regularizer=regularizers.l2(1e-3)))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X, y, epochs=500, verbose=1, callbacks=[callback])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(dataset, dataset_total, test, actual):\n",
    "    n_steps_in, n_steps_out, slide = 6, 2, 1\n",
    "    X, y = split_sequence(dataset, dataset_total, n_steps_in, n_steps_out, slide)\n",
    "    \n",
    "    # flatten input and output\n",
    "    n_input = X.shape[1] * X.shape[2]\n",
    "    X = X.reshape((X.shape[0], n_input))\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "    model = fit(X, y, n_input, n_output)      \n",
    "    \n",
    "    mae, rmse, smape = list(), list(), list()\n",
    "    for i in range(0, len(test)-n_steps_in, n_steps_out):\n",
    "        x_input = array(test[i:n_steps_in+i])\n",
    "        x_input = x_input.reshape((1, n_input, 1))\n",
    "        pred = model.predict(x_input)\n",
    "        mae_aux, rmse_aux, smape_aux = measure_error(actual, pred[0], n_steps_in, n_steps_out, i)\n",
    "        mae.append(mae_aux), rmse.append(rmse_aux), smape.append(smape_aux)\n",
    "    \n",
    "    return mae, rmse, smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(actual, predicted):\n",
    "    if not all([isinstance(actual, np.ndarray), \n",
    "                isinstance(predicted, np.ndarray)]):\n",
    "        actual, predicted = np.array(actual),\n",
    "        np.array(predicted)\n",
    "    return round(np.mean(np.abs(predicted - actual) / ((np.abs(predicted) + np.abs(actual))/2))*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_error(actual, pred, step_in, step_out, index):\n",
    "    #print(actual[index+step_in:index+step_in+step_out],pred,index+step_in,index+step_in+step_out)\n",
    "    #print(len(actual[index+step_in:index+step_in+step_out]),len(pred))\n",
    "    mae = mean_absolute_error(actual[index+step_in:index+step_in+step_out], pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual[index+step_in:index+step_in+step_out], pred))\n",
    "    smape = sMAPE(actual[index+step_in:index+step_in+step_out], pred)\n",
    "    return mae, rmse, smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data Set and Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.pivot_table('nr', 'date', 'abo')\n",
    "df1['Total'] = df1.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 22:33:19.129251: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-06 22:33:19.129280: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-06 22:33:19.129304: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2022-10-06 22:33:19.129743: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 15ms/step - loss: 107349496.0000\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 15952491.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 10213067.0000\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6422296.0000\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 3209928.0000\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2629833.5000\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2419988.2500\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2318845.0000\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2557145.0000\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2532335.5000\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2422621.0000\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2329236.0000\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2277206.7500\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2247742.0000\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2183756.5000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2219047.2500\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2424055.7500\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2216884.0000\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2073171.5000\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2128873.5000\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2198067.5000\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2100560.5000\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2147169.0000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2049406.6250\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2151965.7500\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2170491.7500\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2142438.2500\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2056521.7500\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2030534.2500\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2022794.3750\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2153327.2500\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1993854.0000\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2020123.1250\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1985742.5000\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2090353.6250\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1941364.5000\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2065695.5000\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2157216.2500\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2147835.2500\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2205682.0000\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2121210.7500\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2114424.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2006870.3750\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1923352.5000\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1892194.0000\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1895910.2500\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1885522.1250\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2012772.7500\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2112941.7500\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2016193.6250\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2076659.5000\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1855525.5000\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1853161.0000\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1875430.7500\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2137415.0000\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1987594.6250\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1898835.8750\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1817150.1250\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1930462.3750\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1955856.3750\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1853540.8750\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1947636.6250\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2392100.2500\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2177504.0000\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1912101.8750\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2005168.1250\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1990807.1250\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1979869.5000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1953455.7500\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1886916.2500\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1947998.1250\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2034068.8750\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2172338.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2060499.5000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1914826.2500\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1982768.1250\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2070691.2500\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1938484.0000\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1953732.6250\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1828365.3750\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1757021.0000\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1795513.2500\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1919225.2500\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2179112.5000\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2020181.8750\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1943807.5000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1974314.1250\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1899349.2500\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1970012.6250\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1979448.6250\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1845728.7500\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1877018.0000\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2311278.2500\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2013528.6250\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1957261.7500\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step - loss: 2108640.5000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1898732.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2044463.6250\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1834183.3750\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1807075.0000\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1762945.5000\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1843602.2500\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1811898.6250\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1995189.0000\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1905845.1250\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1773696.0000\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1835312.7500\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1831514.3750\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1806220.1250\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1812916.0000\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2038298.6250\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1750735.5000\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1746735.7500\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1762144.0000\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1850683.0000\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1904034.7500\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1771948.8750\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1742102.6250\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1857864.7500\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1745102.5000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1818999.1250\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1812188.7500\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1899368.2500\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2137761.7500\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2126904.7500\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2090662.8750\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1840478.6250\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1723335.6250\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1738457.0000\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1711573.3750\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1754767.6250\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1875601.6250\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1902209.5000\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1829139.7500\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1997854.6250\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1788879.0000\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1743416.2500\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1870438.1250\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1819863.6250\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1739706.7500\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1809039.2500\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1865462.5000\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1930882.0000\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2015045.2500\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1884747.6250\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2033352.7500\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2163798.2500\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2243779.7500\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1838707.7500\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2076443.8750\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2054242.6250\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2377965.2500\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1990997.1250\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1740149.0000\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2002123.0000\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1825689.8750\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1783694.5000\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1766989.6250\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1915663.0000\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1818492.7500\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1779975.6250\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1959849.6250\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2179913.7500\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2080617.3750\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1785101.3750\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1837036.7500\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2092007.2500\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2211106.0000\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2127700.2500\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2172566.0000\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1840604.5000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1780922.6250\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2026102.2500\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1840773.2500\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1750439.7500\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1788503.3750\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1844083.6250\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1933938.3750\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1787941.0000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1748580.1250\n"
     ]
    }
   ],
   "source": [
    "dataset = df1[['A', 'AB', 'B', 'O']].values\n",
    "dataset_total = df1[['Total']].values\n",
    "mae, rmse, smape = train_predict(dataset[:216], dataset_total[:216], dataset[216:], df1[['Total']][216:].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAFMCAYAAABs233xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcgElEQVR4nO3dT2wb95338Y8rJV074UhZrJL2adhjDIRitghKFBkd2qLqZmSghxUQMEAQIDrQuQTRxb4VOugqXVTkYvngAkGATg34OSxQTR6r2M3BEwQqimzJCRCfHnRapLGxDWfoP9vKWj4HP5yYlkSRI/40/PN+AQbC4XD4VfUtP/r95jfDU81msykAAGDEN7IuAACAUUbQAgBgEEELAIBBBC0AAAYRtACAoRMEQdYldI2gBYAxFMexzp49q5WVlX3Pvfvuuzp79uy+7aVSSaVS6cDtZ8+eTf7Nz8/L87xDn2/9O8zly5cVBIHiONbS0pJKpVJbnWEYynXdttd4ntf2noOEoO0Dkw17VENiPBzUF++++67iOJbUWw+GYZh8eJVKpbbjHPZe9ODo2tra2rft448/3rctCAJNTU0l//247e1tff755/r8889VqVS0vLzc1lePPt/6dxjf91UoFHTp0iU5jqOdnR3V63X5vi9JWltbU6VSaXuN4zj7wndQELR9ZKJhj2pIjI9r164l/bCzs6PPPvtMly5datunmx5cXFxMPrx++9vfKp/P66233mrbhx4cLSsrK8kfVpcvX062W5al2dnZts8h3/f1yiuv7DuG67p69dVXtbCwoN/85jcd369cLsuyLNVqtZ5rXVtbU7lcPvT5MAw1PT2tfD6/7znbtgcybAnaPjHVsMBBLMvSq6++qjAM27Yd1YNxHCuO4+SDzLIsXbx4Uc8///zJFY8T5XmearWadnZ2dO3aNa2vr7eNNB3Hafsc8jxP586d23ecra0tvf766yqXy/r1r3/d8T1d11UcxweG4VE+/PBDFQoFSdLbb78tz/M0Pz+v6elp2bZ94Gi2xbbtgZw+Jmj7yETDAgcJw1Aff/zxvv46qgcty1I+n9fS0lLbB9IvfvEL80UjE5ZlKY5jBUGgfD6vzz//XJZlJc8vLCzoww8/TB5vbW3JcZy2Y/i+r3w+r3w+n4Tg47Nx8/PzyWmG9fV1ra6utgXto8+fPXv2wFNn0sPebr3OsixduXJF29vbWl1dVRAEh45mJSmfz6caRZtG0PaRiYbt1JAYL4uLi22LTZ5//vl9/dVND25vb8u2bW1uburs2bNaXFykB0eYbdsql8taXl5WqVTS2tpa2/OtP76CIDh0Fs7zPAVBkEw/x3G8b4r20dMNOzs7+6Z/Hz8dsbOzs+99jhoFX7p0SRcuXFAYhpqfn1epVGqro/VHxaCZzLqAUfJow0ZRdGTDSkoadnV1Ndlne3s71ZQLRtu1a9eSP85aC5o8z2sL0m56UJIqlYoqlUrSf4uLi9rZ2UlGOvTg6GidKqhUKknfzM3NaXZ2NtmnNRPSaDQOnYV7tCeCINBbb73V9rnVD5ZltZ0OeVRrNGtZlpaXl7WxsaFCoaD5+XktLCy0jdIHDSPaPms1bKdp4+3tbe3s7CTnTA5awAJ0ks/nZdu2qtXqvuc69aDneVpaWkoeW5alSqUysFNuOD7XdZMVwK1FmI+P+lozIb7vy7bttud839fU1FTbH16Hzcb1w2Gj0tZotpMgCJLaBglB22eD1LAYbblcTo1GY9/2Tj1o27ZqtVrbdJvv+4qiqG2Eg9HRWjhUKpX0k5/8RLZt7zudYFlWMhvy+MjwV7/6lV599dV9x33llVd6WuH7+OmIs2fPJpfrPGphYWHfH32PjmYlaXV1VcvLy5qfn1elUkm212o1LSwsdF3TSWHquM9aDTs1NdVzw7amYebn5/ftc+XKlX0fmhhvxWJR6+vr+7Z36kHLsnTt2jWtrKwkr83n8/rlL3/Zti89OFquXLmyb5tlWW3nSa9du9b2fOuSrsMWyj26/aDzrY866vlHXbhwQT//+c/beq1QKLRNU+fzeW1vb+97red5B/6sWTvF99ECAAbJ2tqaXn/99Z7WCfi+ryAIDr30J0sELQBg4MRx3NMCp173P0kdgzaOY4VhqDAMVa1WdfHiRUkPh+et1WGtJdzdbgM6oecwyDzPk+u6bdOT9ByO0nEx1NbWlmq1WnLi3HXd5CL31vy57/tdbwOOQs9hkD2+iIieQzc6Bm25XE7+QmvdraNarSbz5q3r9brdBhyFnsMwoefQja5WHbdu4nzQfSTr9fq+SwwO29ZJs9kUZ4tH0ze+carn19BzOI40PZcGPYeWTj3XVdB6npcsrc7lcoqiqO35brd18uDB/6hev9f1/hgeMzO5nl9Dz+E40vRcGvQcWjr13JFB63leslw6CAIVi8Xkrh1hGGpubi75RpCjtgHdoOcwLA7qTeBxHc/R+r6v9fV1LS4uanFxUVEUyXEchWEo3/cVx3Fyl5FutgFHoecwyHzfV61WS05n0HPoxsBcR7u7u8eUyog6qWm8XtFzo4uew0nr1HPc6xgAAIMIWgAADCJoAQAwiKAFAMAgghYAAIMIWgAADCJoAQAwqKtbMAIARsvvf7+j3/3uE2PHv3Pn4X2gn37a3DXN3//+D/TyyyVjx+8XghYA0HeNxsNbU5oM2mFB0ALAGHr55ZLR0eDm5nuSpPPn3zH2HsOCc7QAABhE0AIAYBBBCwCAQQQtAAAGEbQAABhE0AIAYBBBCwCAQQQtAAAGEbQAABhE0AIAYBBBCwCAQQQtAAAGEbQAABhE0AIAYBBBCwCAQQQtAAAGEbQAABhE0AIAYBBBCwCAQQQtAAAGHRm0nudpaWkpeRwEgebn57W4uKjFxUWtra1JkkqlkpaWlnT58uW21/q+L9d1DZSOUUXPARglk0ft4DhO24dWFEXa3t6W9PAD0LIsSdLGxoZs20728zxPkmTbtlzXle/7bc8Dh6HnAIySI4P2cY9+cIVhKMdxJElxHCsMQ+XzeUlStVrVuXPnJEn5fF5BEHT80JuYOKXp6TO9loMxQM8BGGY9B22L67oql8vJ4yiKNDU1pZWVFa2urqrRaLTtX6/XOx5vb6+pev1e2nIwwGZmcn05Dj2HbvWr54B+SL0Y6saNG22Py+WyLMtSLpeT53nK5XKKoujYBQIt9ByAYZQqaOM4bnvsuq6CIGjbViwWk/3CMNTc3FzKEgF6DsDwOjJofd9XrVZLFppID6fspqenk8cLCwuSvl6M4jiOHMdRGIbyfV9xHLMoBV2j5wCMklPNZrOZdRGStLu7x/myETWo58voudFFz2Vvc/M9SdL58+9kXMnJ6NRz3LACAACDCFoAAAwiaAEAMIigBQDAIIIWAACDCFoAAAwiaAEAMIigBQDAIIIWAACDCFoAAAwiaAEAMCj199EC6J8g+INqtf80dvy7d+9Kkp566ilj7zE7+88qFF4ydnxgWBG0wBi4e/eOJLNBC+BgBC0wAAqFl4yOBl33fUlSufymsfcAcDCCFgCOwfM8WZalMAxVLpezLgcDiMVQAJCS7/vK5/OybVv5fF5BEGRdEgYQQQsAKc3Ozmp5eVlBECgMQxUKhaxLwgBi6hgAUrIsS+VyWcvLy7Jt+8j9JyZOaXr6zAlUlr3JyQlJGpuftxOCFgBS8n1ftm2rUqlobW1NnufJcZxD99/ba6pev3eCFWbnwYM9SRqbn3dmJnfoc0wdA0BKQRAk08Vvv/22oijKuCIMIka0AJBSuVyW67rK5/OsOsahCFoASKl1jhbohKljAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwKAjg9bzPC0tLbVtK5VKWlpa0uXLl9v2831frut23AYchZ4DMEqODNqD7tu5sbGhK1euqFKpSHr44SYpuam27/sHbgO6Qc8BGCWppo7jOFYYhsnjarWqfD4vScl3Mh60DUiLngMwrFLdgjGKIk1NTWllZUWrq6tqNBptz9fr9QO3dTJOXx+F3tFzx8NXlgHZSRW0rXt75nI5eZ6nXC6371srDtrWyTh9fdS46fT1Ud2i546HrywDstPz1LHruvum5IrFouI4liSFYai5ubkDtwFp0HMAhtmRQev7vmq1WrLQZGFhQdLXi1Ecx5HjOArDUL7vK45j2bZ94DagG/QcgFFyqtlsNrMuQpJ2d/fGZlpr3AzqNN449Zzrvi9JKpffzLiSk0HPZW9z8z1J0vnz72Rcycno1HPcsAIAAIP44vcDfPZZVUHwB2PHv3fvriTpzJmnjL1HofCSXnyxaOz4AIDuELQZuHvXfNACAAYDQXuAF18sGh0NXr36gSTptdfeMPYeAIDBwDlaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwKDJrAsAAOz3b//2v/XFF3/OuozUWrVvbr6XcSXpffvb39HPfvavxz4OQQsAA+iLL/6sP/7p/+r01OmsS0mlOdmUJN1ufJlxJencj+737VgELQAMqNNTp/XCD1/IuoyxdPOjm307FudoAQAwiKAFAMAgghYAAIOODFrP87S0tJQ8juNYQRDI8zytra0l20ulkpaWlnT58uW21/q+L9d1+1w2Rhk9B2CUHBm0juO0Pd7a2lKtVku2tz7QNjY2dOXKFVUqFUkPP/AkybZtSZLv+/2rGiONngMwSnqeOi6XyyqXy5KkMAyVz+clPRx1hGGY7FetVpPn8vm8giDoR70YQ/QcgGGW+vKeMAw1PT2djB6iKNLU1JRWVla0urqqRqPRtn+9Xu94vImJU5qePpO2nKEyOTkhSWPz8/YLPZcePQdkJ3XQep6n1dXV5HFrxJHL5eR5nnK5nKIo6vp4e3tN1ev30pYzVB482JOksfl5Z2ZyfTkOPZcePQdkJ9WqY8/zkvNiQRDIdd1903TFYlFxHEt6OBKZm5s7ZqkYZ/QcgGF1ZND6vq9arZYsNPF9X+vr61pcXNTi4qKiKNLCwoKkrxejOI4jx3EUhqF831ccx8l0H3AUeg7AKDnVbDabWRchSbu7e2MzrXX16geSpNdeeyPjSk7GoE7jjVPPue77kqRy+c2MKzkZo9Bzm5vv6XbjS27BmJGbH93UTO45nT//Tlf7d+o57nUMAMcQBEGy+v3xS9MAiTtDAcCxXLp0SY7jKIqitsvNgBZGtACQkuu6KhaLCsMwWQXfSS+XlLUuyUJ2Jicn+nJJHEELACn98Y9/lKTkeu4LFy7IsqxD9+/lkrLWJVnIzoMH3Z9T73SOlqljADiG7373u7IsS4VCgXts40AELQCkVCwWk/+O47jjaBbji6AFgJQcx1Ecx8kXWHRznhbjh3O0AHAMrTuWcYMUHIYRLQAABhG0AAAYRNACAGAQ52iBLvz7v/8f3br1ZdZlpNaqvXXP42H07LPP6cc//pesywB6RtACXbh160t98Ze/6Ompf8y6lFQmnvwHSVLj/t8zriSdO9Ffsy4BSI2gBbr09NQ/6ntzC1mXMZY+vbGVdQlAapyjBQDAIIIWAACDCFoAAAwiaAEAMIigBQDAIIIWAACDCFoAAAwiaAEAMIigBQDAoKG8M9R//Me2bt8e3vvO3r59S5J09eoHGVeSzszMc/rRj+azLgMAhsJQBu3t21/q1pd/0TO5Z7IuJZVvTj4pSdq997eMK+ndV42vsi4BAIbKUAatJD2Te0Y//cFPsy5j7Fz/5HrWJQDAUOEcLQAABhG0AAAYRNACAGAQQQsAgEFHBq3neVpaWtq3zfd9ua7b8zbgKPQcgFFyZNA6jtP22PM8SZJt25Ik3/e73gZ0g54DMEp6vrynWq3q3LlzkqR8Pq8gCFSv17va1voAPMjExClNT5/prujJCe32Wjj6ZnJyouvfVT8MSs8hWyfdd0C/9By0jUaj7XG9Xu96Wyd7e03V6/e6quHBg72u9oMZDx7sdf27kqSZmdyx3o+eg9Rb3x2354B+6nkxVC6XUxRFqbYBadBzAIZZzyPaYrGoOI4lSWEYam5uTnEcd7UNSIOeAzDMjhzR+r6vWq2WLDRxHEdhGMr3fcVxLNu2u94GdIOeAzBKTjWbzWbWRUjS7m7351+uXv1Au/f+xr2OM3D9k+t64sw39dprb3T9mkE9X9ZLz7nu+2rc/7u+N7dguCoc5NMbW8qdflLl8ptd7T8KPbe5+Z5uN77UCz98wXBVOMjNj25qJveczp9/p6v9O/UcN6wAAMAgghYAAIOG9mvyAGCUNRoN3avf082PbmZdyli6V7+nhhpH79gFRrQAABjEiBYABlAul9N/6x6LoTJy86ObyuX6s6iOES0AAAYRtAAAGETQAgBgEEELAIBBBC0AAAYRtAAAGETQAgBgEEELAIBBBC0AAAYRtAAAGETQAgBgEEELAIBBBC0AAAYRtAAAGETQAgBgEEELAIBBBC0A9MHa2lrWJWBAEbQAcEy+7ysMw6zLwIAiaAHgGMIwVD6fz7oMDLDJrAsAgGEWhqFs2+5q34mJU5qePtPVvpOTE8cpC30wOTnR9e+r43H6UAsAjCXf97sOWUna22uqXr/X1b4PHuylLQt98uDBXte/r5mZ3KHPEbQAkNLU1JR831ccx/rTn/6kIAhUKBSyLgsDhnO0AJBSoVCQbduKokhxHGddDgYUI1oAOKZyuaxyuZx1GRhQPQdtEARaXl6WZVmSpFdeeUUXL15UqVTS7OysbNtWpVKRJHmeJ8uyFIYhTYjU6DkAw6znoI2iSNvb25IefgC2Pvw2NjbaFgV4nidJsm1bruv2vGgAaKHnAAyznoP20Q+uMAzlOI4kKY7jtuvJqtWqzp07J0nK5/MKgqDjh16vy953ey0cfdOvJe/dGpSeQ7ZOuu+Afkl9jtZ13bapuSiKNDU1pZWVFa2urqrRaLTtX6/XOx6PZe/Do5cl71LnZe+9oOfGW78utQBOWupVxzdu3Gh7XC6XZVmWcrmcPM9TLpdTFEXHLhBooecADKNUI9rHl7G7rqvZ2dm268eKxWKyXxiGmpubO0aZ7e7du6s7jYauf3K9b8dEd75qfKWndfKjhax77u7dO7rTaOjTG1t9Oya6dyf6L33jfxilYjilGtFGUaTp6enk8cLCgqSvF6M4jiPHcRSGYXIxN4tScBz0HIBhdarZbDazLkKSdne7P/9y9eoH2r33N/30Bz81XBUed/2T63rizDf12mtvdP2aQT1f1kvPue77atz/u743t2C4Khzk0xtbyp1+UuXym13tPwo9t7n5nm43vtQLP3zBcFU4yM2Pbmom95zOn3+nq/079Rx3hgIAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgwhaAAAMImgBADCIoAUAwCCCFgAAgyazLgAYFneiv+rTG1tZl5HK3/92X5L05DdPZ1xJOneivyp3+ltZlwGkQtACXXj22eeyLuFYbjW+kiTlpqcyriSd3OlvDf3vAOOLoAW68OMf/0vWJRyL674vSSqX38y4EmD8cI4WAACDCFoAAAwiaAEAMIigBQDAoFSLoUqlkmZnZ2XbtiqViiTJ8zxZlqUwDFUulw/dBqRBzwEYVqmCdmNjQ7ZtJ489z5Mk2bYt13Xl+77iON637dHXAL2g5zCO7kf3dfOjm1mXkcruf+9Kkp74hycyriSd+9F9KdefY6UK2jiOFYah8vm8JKlarercuXOSpHw+ryAIVK/X923jQw9p0XMYN9/+9neyLuFYvrjzZ0nSTG5Ir3/O9e93kCpooyjS1NSUVlZWtLq6qkaj0fZ8vV4/cFsnExOnND19pqv3n5yc0K3GV7r+yfWe6h4U9///XXpOD+Fder5qfKX/ZX2n699Vv2Tdc8NucnJCksbm5x0FP/vZv2ZdwrFsbr4nSTp//p2MK8leqqBtnfvK5XLyPE+5XE5RFLXtc9C2Tvb2mqrX73W17zPP/JMePNjrvuABU7/78H8X65npbAtJ4dkz39Izz/xT178rSZqZOf78S9Y9N+xa/38Zl5+3Hz0H9EvPQeu6rmZnZ1UoFJJtxWIxOT8WhqHm5uYUx/G+bf3yox/N9+1YWbh69QNJ0muvvZFxJcNhEHoOANLq+fKehYUFSV8vRnEcR47jKAzDZEGKbdsHbgPSoOcADLNTzWazmXURkrS7uzc201rjNqId1Gm8ceq5cbvXMT2XvXE7R9up57hhBQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGBQqlswAgC+/rKLMAxVrVZ18eLFrEvCAGJECwApbW1tqVaryXEcSQ9vFwo8jhEtAKTU+rILqbv7a/ONUeOJoAWAYwrDUNPT00feX5tvjBpd3IIRAAzyPE+rq6tZl4EBRdACwDF4nqdKpSJJCoIg42owiJg6BgZAEPxBtdp/Gjv+rVtfSvr6W3xMmJ39ZxUKLxk7/iDyfV/r6+va3NyUJF24cCHjijCICFpgDDz11NNZlzCSbNvW9vZ21mVgwBG0wAAoFF4au9EgMC44RwsAgEEELQAABjF1DABj6Pe/39HvfveJseN/8cWfJUmbm+8Ze4/vf/8HevnlkrHj9wtBCwDou1zOyrqEgXGq2Ww2sy5CknZ39wbmDiKffVZVEPzB2PFv374lSZqZedbYexQKL+nFF4vGjt+LTndMydIg9Rz6i57DSevUc4xoM/DUU09lXQIA4IQQtAd48cXiwIwGAQDDjVXHAAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGBQz5f3xHGsMAwVhqGq1aouXrwoSSqVSpqdnZVt28mXIHueJ8uyFIahyuVyfyvH2KDnAAyznke0W1tbqtVqchxHkuS6riRpY2NDV65cafvAkx5+X6P08AuSgTToOQDDrOegLZfLyUghDEPl83lJX486WqrVavJcPp9XEAT9qBdjiJ4DMMxS3xkqDENNT08no4coijQ1NaWVlRWtrq6q0Wi07V+v1zseb2LilKanz6QtB2OAngMwjFIHred5Wl1dTR63Rhy5XE6e5ymXyymKoq6Pt7fX5GbbI6pfN3in59CtQf1SAYynVKuOPc9LzosFQSDXdfdN0xWLRcVxLOnhSGRubu6YpWKc0XMAhlXPQev7vtbX17W4uKjFxUVFUaSFhQVJXy9GcRxHjuMoDEP5vq84jpPpPqBX9ByAYcb30cK4QZ3Go+dGFz2Hk9ap57hhBQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEEELQAABhG0AAAYNGny4J7nybIshWGocrls8q0ASfQcTh49h6MYG9F6nidJsm1bkuT7vqm3AiTRczh59By6YWxEW61Wde7cOUlSPp9XEARJMx7kiScmNDOTM1UOxgA9h5NGz6Ebxka0jUaj7XG9Xjf1VoAkeg4nj55DN4wFbS6XUxRFpg4P7EPP4aTRc+iGsaAtFouK41iSFIah5ubmTL0VIImew8mj59ANY0HrOI7CMJTv+4rjuON5C6Af6DmcNHoO3TjVbDabWRcBAMCo4oYVAAAYRNACAGAQQQsAgEEELQAABhG0AAAYRNACAGAQQQsAgEH/D6b1gttHZ2xMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 481.89x340.157 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, sharex=True, figsize=(17*cm,12*cm))\n",
    "sns.boxplot(ax=axes[0], y=mae, color='thistle', showfliers=False)\n",
    "axes[0].set_title('MAE')\n",
    "axes[0].set(ylim=(0, 2000))\n",
    "sns.boxplot(ax=axes[1], y=rmse, color='lightsteelblue', showfliers=False)\n",
    "axes[1].set_title('RMSE')\n",
    "axes[1].set(ylim=(0, 2000))\n",
    "sns.boxplot(ax=axes[2], y=smape, color='darkseagreen', showfliers=False)\n",
    "axes[2].set_title('sMAPE (\\%)')\n",
    "axes[2].set(ylim=(0, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/demand_mlp_monthly_abo_boxplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'demand_mlp_month_abo' (list)\n"
     ]
    }
   ],
   "source": [
    "demand_mlp_month_abo = [mae,rmse,smape]\n",
    "%store demand_mlp_month_abo "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_Youtube.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
