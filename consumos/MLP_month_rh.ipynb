{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nRSlxT4q5EHJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 22:31:08.188120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-06 22:31:08.188148: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from numpy import array\n",
    "from datetime import datetime\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "cm = 1/2.54 \n",
    "colors = ['#4477AA', '#EE6677', '#228833', '#CCBB44', '#66CCEE', '#AA3377', '#BBBBBB']\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values with Zero and Group by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2fRF6mEW5QbK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('consumos_rh.csv', parse_dates=['date'])\n",
    "df = df.set_index('date')\n",
    "df = df.groupby('rh').resample('M').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batches of training data (12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, sequence_total, n_steps_in, n_steps_out, slide):\n",
    "    X, y = list(), list()\n",
    "    for i in range(0, len(sequence), slide):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence_total[end_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and fit MLP model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, n_steps_in, n_steps_out):\n",
    "    callback = EarlyStopping(monitor='loss', patience=50)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(800, activation='relu', input_shape=(n_steps_in,)))\n",
    "    model.add(Dense(800, activation='relu', \n",
    "                kernel_regularizer=regularizers.l1_l2(l1=1e-3, l2=1e-3),\n",
    "                bias_regularizer=regularizers.l2(1e-3)))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X, y, epochs=500, verbose=1, callbacks=[callback])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(dataset, dataset_total, test, actual):\n",
    "    n_steps_in, n_steps_out, slide = 6, 2, 1\n",
    "    X, y = split_sequence(dataset, dataset_total, n_steps_in, n_steps_out, slide)\n",
    "    \n",
    "    # flatten input and output\n",
    "    n_input = X.shape[1] * X.shape[2]\n",
    "    X = X.reshape((X.shape[0], n_input))\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "    model = fit(X, y, n_input, n_output)      \n",
    "    \n",
    "    mae, rmse, smape = list(), list(), list()\n",
    "    for i in range(0, len(test)-n_steps_in, n_steps_out):\n",
    "        x_input = array(test[i:n_steps_in+i])\n",
    "        x_input = x_input.reshape((1, n_input, 1))\n",
    "        pred = model.predict(x_input)\n",
    "        mae_aux, rmse_aux, smape_aux = measure_error(actual, pred[0], n_steps_in, n_steps_out, i)\n",
    "        mae.append(mae_aux), rmse.append(rmse_aux), smape.append(smape_aux)\n",
    "    \n",
    "    return mae, rmse, smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sMAPE(actual, predicted):\n",
    "    if not all([isinstance(actual, np.ndarray), \n",
    "                isinstance(predicted, np.ndarray)]):\n",
    "        actual, predicted = np.array(actual),\n",
    "        np.array(predicted)\n",
    "    return round(np.mean(np.abs(predicted - actual) / ((np.abs(predicted) + np.abs(actual))/2))*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_error(actual, pred, step_in, step_out, index):\n",
    "    #print(actual[index+step_in:index+step_in+step_out],pred,index+step_in,index+step_in+step_out)\n",
    "    #print(len(actual[index+step_in:index+step_in+step_out]),len(pred))\n",
    "    mae = mean_absolute_error(actual[index+step_in:index+step_in+step_out], pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual[index+step_in:index+step_in+step_out], pred))\n",
    "    smape = sMAPE(actual[index+step_in:index+step_in+step_out], pred)\n",
    "    return mae, rmse, smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data Set and Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.pivot_table('nr', 'date', 'rh')\n",
    "df1['Total'] = df1.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 22:31:10.557942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-06 22:31:10.557980: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-06 22:31:10.558005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2022-10-06 22:31:10.558386: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 19ms/step - loss: 96082352.0000\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 12417576.0000\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 8035368.5000\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 4906041.0000\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 3024310.2500\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2430893.0000\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2213665.0000\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2355811.7500\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2391489.7500\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2432396.0000\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2246223.0000\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2159643.0000\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2256933.7500\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2205335.5000\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2208420.5000\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2203205.2500\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2308758.0000\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2228518.0000\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2080839.7500\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1983057.8750\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1969135.8750\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1957922.8750\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1918853.5000\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2024238.1250\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1913366.5000\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1997078.3750\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1936644.1250\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1929364.0000\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1920304.8750\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2217950.2500\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2169629.5000\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2078503.0000\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1940766.6250\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2028450.2500\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2038932.6250\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2141720.7500\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1915807.3750\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1975405.8750\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1933402.6250\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1861490.5000\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2001293.7500\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2005148.0000\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2105011.5000\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 2079499.6250\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2023616.1250\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1942555.5000\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2388369.0000\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2002116.8750\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1914725.2500\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1868845.7500\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1834283.6250\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1950787.2500\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2003422.8750\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2172373.0000\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1938812.1250\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1869569.6250\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2020566.5000\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2042234.0000\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1967824.7500\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2064413.0000\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1957653.3750\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2010980.7500\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2015113.5000\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2085400.6250\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2455495.7500\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2244171.2500\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2018797.3750\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1865413.0000\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1886661.5000\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1929914.7500\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1902866.1250\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1960776.0000\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1904542.0000\n",
      "Epoch 74/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1998181.5000\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1962109.5000\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1977335.3750\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1942871.8750\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1997400.3750\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1869619.6250\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1900155.2500\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1805544.6250\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2044625.7500\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1840851.7500\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1773795.2500\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1932339.6250\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2141573.0000\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2344130.7500\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2173999.5000\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 2019624.2500\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1959478.0000\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2162016.2500\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2034427.2500\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1916099.2500\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1929716.6250\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1941343.8750\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 2018430.0000\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1965189.0000\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 2125045.2500\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1950031.7500\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1985882.6250\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1885701.8750\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1898504.2500\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2092363.1250\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2069331.8750\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2148735.5000\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2320846.2500\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 2289639.0000\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1911156.3750\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2229054.7500\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2333663.7500\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2166598.5000\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1901293.5000\n",
      "Epoch 113/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1894579.5000\n",
      "Epoch 114/500\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 2051005.1250\n",
      "Epoch 115/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1917779.1250\n",
      "Epoch 116/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2050901.2500\n",
      "Epoch 117/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1995826.6250\n",
      "Epoch 118/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1856897.1250\n",
      "Epoch 119/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1797345.2500\n",
      "Epoch 120/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1803589.5000\n",
      "Epoch 121/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1851286.3750\n",
      "Epoch 122/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1819396.2500\n",
      "Epoch 123/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1765752.6250\n",
      "Epoch 124/500\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1807326.5000\n",
      "Epoch 125/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1839983.5000\n",
      "Epoch 126/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1802531.3750\n",
      "Epoch 127/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1815460.2500\n",
      "Epoch 128/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1904518.2500\n",
      "Epoch 129/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2031186.1250\n",
      "Epoch 130/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1892637.5000\n",
      "Epoch 131/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1878041.2500\n",
      "Epoch 132/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1933127.3750\n",
      "Epoch 133/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1969682.2500\n",
      "Epoch 134/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1758392.6250\n",
      "Epoch 135/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1828044.0000\n",
      "Epoch 136/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1812832.1250\n",
      "Epoch 137/500\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1813169.6250\n",
      "Epoch 138/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1943506.1250\n",
      "Epoch 139/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2015922.3750\n",
      "Epoch 140/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2093086.1250\n",
      "Epoch 141/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2025508.2500\n",
      "Epoch 142/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2035761.0000\n",
      "Epoch 143/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1858991.6250\n",
      "Epoch 144/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1805346.0000\n",
      "Epoch 145/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1881523.1250\n",
      "Epoch 146/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1933228.1250\n",
      "Epoch 147/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1813000.6250\n",
      "Epoch 148/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1859965.3750\n",
      "Epoch 149/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1792609.3750\n",
      "Epoch 150/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1706721.2500\n",
      "Epoch 151/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1899740.0000\n",
      "Epoch 152/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2247521.7500\n",
      "Epoch 153/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2217835.0000\n",
      "Epoch 154/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1951642.6250\n",
      "Epoch 155/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1819617.8750\n",
      "Epoch 156/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1827779.0000\n",
      "Epoch 157/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1806555.7500\n",
      "Epoch 158/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1798910.8750\n",
      "Epoch 159/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1731133.1250\n",
      "Epoch 160/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1945570.7500\n",
      "Epoch 161/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1884921.8750\n",
      "Epoch 162/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1811714.7500\n",
      "Epoch 163/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1752539.3750\n",
      "Epoch 164/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1806655.3750\n",
      "Epoch 165/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1786966.5000\n",
      "Epoch 166/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1858382.1250\n",
      "Epoch 167/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1877648.2500\n",
      "Epoch 168/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1805225.5000\n",
      "Epoch 169/500\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1925822.7500\n",
      "Epoch 170/500\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1891303.3750\n",
      "Epoch 171/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1848035.5000\n",
      "Epoch 172/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1824645.2500\n",
      "Epoch 173/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1730555.1250\n",
      "Epoch 174/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1894289.5000\n",
      "Epoch 175/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2017237.7500\n",
      "Epoch 176/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1852268.7500\n",
      "Epoch 177/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1754981.2500\n",
      "Epoch 178/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1845038.3750\n",
      "Epoch 179/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2046387.5000\n",
      "Epoch 180/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2094399.7500\n",
      "Epoch 181/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2305576.7500\n",
      "Epoch 182/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2028209.1250\n",
      "Epoch 183/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 2084102.1250\n",
      "Epoch 184/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1941616.8750\n",
      "Epoch 185/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1840853.6250\n",
      "Epoch 186/500\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1824746.0000\n",
      "Epoch 187/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1869988.7500\n",
      "Epoch 188/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1839923.2500\n",
      "Epoch 189/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1895344.2500\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step - loss: 1782838.8750\n",
      "Epoch 191/500\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1719974.3750\n",
      "Epoch 192/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2103997.7500\n",
      "Epoch 193/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2192204.5000\n",
      "Epoch 194/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2074951.2500\n",
      "Epoch 195/500\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1990449.7500\n",
      "Epoch 196/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1815627.1250\n",
      "Epoch 197/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1830422.5000\n",
      "Epoch 198/500\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1754103.8750\n",
      "Epoch 199/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1828448.8750\n",
      "Epoch 200/500\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2010919.7500\n"
     ]
    }
   ],
   "source": [
    "dataset = df1[['+', '-']].values\n",
    "dataset_total = df1[['Total']].values\n",
    "mae, rmse, smape = train_predict(dataset[:216], dataset_total[:216], dataset[216:], df1[['Total']][216:].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 481.89x340.157 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, sharex=True, figsize=(17*cm,12*cm))\n",
    "sns.boxplot(ax=axes[0], y=mae, color='thistle', showfliers=False)\n",
    "axes[0].set_title('MAE')\n",
    "axes[0].set(ylim=(0, 2000))\n",
    "sns.boxplot(ax=axes[1], y=rmse, color='lightsteelblue', showfliers=False)\n",
    "axes[1].set_title('RMSE')\n",
    "axes[1].set(ylim=(0, 2000))\n",
    "sns.boxplot(ax=axes[2], y=smape, color='darkseagreen', showfliers=False)\n",
    "axes[2].set_title('sMAPE (\\%)')\n",
    "axes[2].set(ylim=(0, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/demand_mlp_monthly_rh_boxplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'demand_mlp_month_rh' (list)\n"
     ]
    }
   ],
   "source": [
    "demand_mlp_month_rh = [mae,rmse,smape]\n",
    "%store demand_mlp_month_rh"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_Youtube.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
